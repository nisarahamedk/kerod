{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1jVKNjhdLFUQ"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting git+https://github.com/EmGarr/kerod.git\n",
      "  Cloning https://github.com/EmGarr/kerod.git to /tmp/pip-req-build-d49hzc85\n",
      "  Running command git clone -q https://github.com/EmGarr/kerod.git /tmp/pip-req-build-d49hzc85\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from kerod==0.1) (1.6.2)\n",
      "Requirement already satisfied: matplotlib in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from kerod==0.1) (3.4.1)\n",
      "Requirement already satisfied: tensorflow-addons in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from kerod==0.1) (0.12.1)\n",
      "Requirement already satisfied: tensorflow>=2.4.0 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from kerod==0.1) (2.4.1)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from tensorflow>=2.4.0->kerod==0.1) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from tensorflow>=2.4.0->kerod==0.1) (3.3.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from tensorflow>=2.4.0->kerod==0.1) (1.15.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from tensorflow>=2.4.0->kerod==0.1) (2.4.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from tensorflow>=2.4.0->kerod==0.1) (2.4.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from tensorflow>=2.4.0->kerod==0.1) (1.6.3)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from tensorflow>=2.4.0->kerod==0.1) (3.15.7)\n",
      "Requirement already satisfied: gast==0.3.3 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from tensorflow>=2.4.0->kerod==0.1) (0.3.3)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from tensorflow>=2.4.0->kerod==0.1) (1.19.5)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from tensorflow>=2.4.0->kerod==0.1) (1.32.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from tensorflow>=2.4.0->kerod==0.1) (0.12.0)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from tensorflow>=2.4.0->kerod==0.1) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from tensorflow>=2.4.0->kerod==0.1) (1.1.2)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from tensorflow>=2.4.0->kerod==0.1) (0.36.2)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from tensorflow>=2.4.0->kerod==0.1) (3.7.4.3)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from tensorflow>=2.4.0->kerod==0.1) (1.12.1)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from tensorflow>=2.4.0->kerod==0.1) (1.12)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from tensorflow>=2.4.0->kerod==0.1) (1.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow>=2.4.0->kerod==0.1) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow>=2.4.0->kerod==0.1) (2.25.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow>=2.4.0->kerod==0.1) (52.0.0.post20210125)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow>=2.4.0->kerod==0.1) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow>=2.4.0->kerod==0.1) (0.4.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow>=2.4.0->kerod==0.1) (1.8.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow>=2.4.0->kerod==0.1) (1.28.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.4.0->kerod==0.1) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.4.0->kerod==0.1) (4.2.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.4.0->kerod==0.1) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.4.0->kerod==0.1) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.4.0->kerod==0.1) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.4.0->kerod==0.1) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.4.0->kerod==0.1) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.4.0->kerod==0.1) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.4.0->kerod==0.1) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.4.0->kerod==0.1) (2020.12.5)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.4.0->kerod==0.1) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.4.0->kerod==0.1) (3.4.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from matplotlib->kerod==0.1) (8.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from matplotlib->kerod==0.1) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from matplotlib->kerod==0.1) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from matplotlib->kerod==0.1) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from matplotlib->kerod==0.1) (2.8.1)\n",
      "Requirement already satisfied: typeguard>=2.7 in /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages (from tensorflow-addons->kerod==0.1) (2.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade git+https://github.com/EmGarr/kerod.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CET-72i5EmKn"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../kerod/src/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ews_7qF9OBi8"
   },
   "source": [
    "# Download COCO/2017\n",
    "\n",
    "Download and preprocess COCO/2017 to the following format (required by od networks):\n",
    "\n",
    "```python\n",
    "dataset = {\n",
    "        'images' : A tensor of float32 and shape [1, height, widht, 3],\n",
    "        'images_info': A tensor of float32 and shape [1, 2] ,\n",
    "        'bbox': A tensor of float32 and shape [1, num_boxes, 4],\n",
    "        'labels': A tensor of int32 and shape [1, num_boxes],\n",
    "        'num_boxes': A tensor of int32 and shape [1, 1],\n",
    "        'weights': A tensor of float32 and shape [1, num_boxes]\n",
    "    }\n",
    "```\n",
    "\n",
    "If you need to download the dataset in a specific directory you can use the argument `data_dir` of `tfds.load`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1cC2k8osNGFw",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from kerod.dataset.preprocessing import preprocess, expand_dims_for_single_batch\n",
    "from kerod.core.standard_fields import BoxField\n",
    "\n",
    "ds_train, ds_info = tfds.load(name=\"coco/2017\", split=\"train\", shuffle_files=True, with_info=True)\n",
    "ds_train = ds_train.map(functools.partial(preprocess, bgr=True), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "# Filter example with no boxes after preprocessing\n",
    "ds_train =  ds_train.filter(lambda x, y: tf.shape(y[BoxField.BOXES])[0] > 1)\n",
    "ds_train = ds_train.map(expand_dims_for_single_batch, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "ds_test = tfds.load(name=\"coco/2017\", split=\"validation\", shuffle_files=False)\n",
    "ds_test = ds_test.map(\n",
    "    functools.partial(preprocess, horizontal_flip=False, bgr=True),\n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "# Filter example with no boxes after preprocessing\n",
    "ds_test =  ds_test.filter(lambda x, y: tf.shape(y[BoxField.BOXES])[0] > 1)\n",
    "ds_test = ds_test.map(expand_dims_for_single_batch, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train, ds_info = tfds.load(name=\"coco/2017\", split=\"train\", shuffle_files=True, with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor([61 71 71 71], shape=(4,), dtype=int64)\ntf.Tensor([2 2 8 8 8 8 8 8 8 2 8 8 8 8 2 8 8], shape=(17,), dtype=int64)\ntf.Tensor([ 0  0 36 36], shape=(4,), dtype=int64)\ntf.Tensor([39 39 39 39 39 39 39 39 39 40 40 40 40  0  0 40 40 40 40], shape=(19,), dtype=int64)\ntf.Tensor([ 0  0 29  2], shape=(4,), dtype=int64)\ntf.Tensor([5 5 0 0], shape=(4,), dtype=int64)\ntf.Tensor([ 1  5  5  5  0  0 10 24  0  0  1  1 10  0  1  1  1  1  0 26], shape=(20,), dtype=int64)\ntf.Tensor([11], shape=(1,), dtype=int64)\ntf.Tensor([39 39 39 63 66 64], shape=(6,), dtype=int64)\ntf.Tensor([14 14 14 14 14 14 14 14], shape=(8,), dtype=int64)\ntf.Tensor([ 0  0  0  0 30 30 30], shape=(7,), dtype=int64)\ntf.Tensor([57 75], shape=(2,), dtype=int64)\ntf.Tensor([3 3 0 3], shape=(4,), dtype=int64)\ntf.Tensor([ 6  0  0  1 24 24  0  0], shape=(8,), dtype=int64)\ntf.Tensor([16 29  0  0  0  0  0  0  0  0  0  0  0 25], shape=(14,), dtype=int64)\ntf.Tensor([ 0  0 31 31  0  0], shape=(6,), dtype=int64)\ntf.Tensor([ 0 40 65  0], shape=(4,), dtype=int64)\ntf.Tensor([ 0 30], shape=(2,), dtype=int64)\ntf.Tensor([ 0  0 36], shape=(3,), dtype=int64)\ntf.Tensor([5 0 0 0 0 0], shape=(6,), dtype=int64)\ntf.Tensor([2 5 9 0], shape=(4,), dtype=int64)\ntf.Tensor([56  0 53 56], shape=(4,), dtype=int64)\ntf.Tensor([48 41 73], shape=(3,), dtype=int64)\ntf.Tensor([ 0  0  0  0  0  0  0 21 21  0  0  0], shape=(12,), dtype=int64)\ntf.Tensor([67  0], shape=(2,), dtype=int64)\ntf.Tensor([31  0], shape=(2,), dtype=int64)\ntf.Tensor(\n[2 2 2 2 2 2 2 2 2 5 0 0 0 0 3 3 3 3 3 0 9 0 0 0 7 9 0 1 2 3 3 3 3 3 3 3 0\n 0 2 3 9 9 0 2 2 0 2 3], shape=(48,), dtype=int64)\ntf.Tensor([6 0 0 0 0 0 0 0 0 0 0 0 0], shape=(13,), dtype=int64)\ntf.Tensor([13 14  0], shape=(3,), dtype=int64)\ntf.Tensor([ 2  2  2  2  5  0  0  0  0  0  0  0  9  9 36  2  9  0 26 26  7], shape=(21,), dtype=int64)\ntf.Tensor([49 55], shape=(2,), dtype=int64)\ntf.Tensor([32 34  0  0  0  0  0  0  0  0 13 35 35 35 35 13], shape=(16,), dtype=int64)\ntf.Tensor([15 57 56 56], shape=(4,), dtype=int64)\ntf.Tensor([61 71], shape=(2,), dtype=int64)\ntf.Tensor([14 14 14 14 14 14], shape=(6,), dtype=int64)\ntf.Tensor([32  0 38], shape=(3,), dtype=int64)\ntf.Tensor([ 0  0  0  0  0  0  0 33 33 33 33 33  0], shape=(13,), dtype=int64)\ntf.Tensor(\n[ 2  2  2 60 60 60 74 41 41 41 41 75 75  0  0  0  0  0  0  0  0  0  0 41\n 41 41 41 41 41 41 41 42 56 56 56 56 56 56 56 56 56 56 56 60 60 60 60 60\n 60 75  0 42 56 60  0  2  2 41 56  0 60 60  0 41 56], shape=(65,), dtype=int64)\ntf.Tensor([27  0  0], shape=(3,), dtype=int64)\ntf.Tensor([23], shape=(1,), dtype=int64)\ntf.Tensor([ 0 77], shape=(2,), dtype=int64)\ntf.Tensor([13], shape=(1,), dtype=int64)\ntf.Tensor([50], shape=(1,), dtype=int64)\ntf.Tensor([58 39 39 56 60 60  0  0 40 27 56], shape=(11,), dtype=int64)\ntf.Tensor([ 0 54 54 54 54 54], shape=(6,), dtype=int64)\ntf.Tensor([23 23], shape=(2,), dtype=int64)\ntf.Tensor([21], shape=(1,), dtype=int64)\ntf.Tensor([11  0  7], shape=(3,), dtype=int64)\ntf.Tensor([23 23 23 23 23 23 23], shape=(7,), dtype=int64)\ntf.Tensor([42 55 60], shape=(3,), dtype=int64)\ntf.Tensor([ 1  2  0  0  7 24], shape=(6,), dtype=int64)\ntf.Tensor([ 0  0  0  0 36], shape=(5,), dtype=int64)\ntf.Tensor([39 48 60], shape=(3,), dtype=int64)\ntf.Tensor([ 5  9  9  9 74 74  0], shape=(7,), dtype=int64)\ntf.Tensor([14 14 14 14 14 14 14 14 14 14 14 14  2  0  0  0  3 14  0 13 14], shape=(21,), dtype=int64)\ntf.Tensor([2 2 7 0 7 7 2], shape=(7,), dtype=int64)\ntf.Tensor([15 56], shape=(2,), dtype=int64)\ntf.Tensor([9 9], shape=(2,), dtype=int64)\ntf.Tensor([12 12 12], shape=(3,), dtype=int64)\ntf.Tensor([61 58], shape=(2,), dtype=int64)\ntf.Tensor([ 0 30], shape=(2,), dtype=int64)\ntf.Tensor([16  2  2 11 13 45  2 16], shape=(8,), dtype=int64)\ntf.Tensor([6], shape=(1,), dtype=int64)\ntf.Tensor([5 0 0], shape=(3,), dtype=int64)\ntf.Tensor([44 45 60 63 41], shape=(5,), dtype=int64)\ntf.Tensor([50], shape=(1,), dtype=int64)\ntf.Tensor([75 75 78 41 61 71 71], shape=(7,), dtype=int64)\ntf.Tensor([ 0  0 29], shape=(3,), dtype=int64)\ntf.Tensor([ 7 10  7  2  2], shape=(5,), dtype=int64)\ntf.Tensor([2 6], shape=(2,), dtype=int64)\ntf.Tensor([74 56  0  0 69 28 41 41 60], shape=(9,), dtype=int64)\ntf.Tensor([48 52 48], shape=(3,), dtype=int64)\ntf.Tensor([14 14], shape=(2,), dtype=int64)\ntf.Tensor([ 8  8  8  8 13  0  0  0  0  0  0  0  0  0  0  0 13  0  0  8  0], shape=(21,), dtype=int64)\ntf.Tensor([2 9 2], shape=(3,), dtype=int64)\ntf.Tensor([19 19], shape=(2,), dtype=int64)\ntf.Tensor([2 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0], shape=(16,), dtype=int64)\ntf.Tensor([77], shape=(1,), dtype=int64)\ntf.Tensor([36  0  0  0  0  0  0  0  0  0  0  0  0  0  0], shape=(15,), dtype=int64)\ntf.Tensor([17  0  0  0  0  0  0  0  0  0  0  0], shape=(12,), dtype=int64)\ntf.Tensor([39 56 60 72 41 69 71 41 45 39 39], shape=(11,), dtype=int64)\ntf.Tensor([45 45 47 49 49], shape=(5,), dtype=int64)\ntf.Tensor([4 4], shape=(2,), dtype=int64)\ntf.Tensor([48 60 41], shape=(3,), dtype=int64)\ntf.Tensor([15], shape=(1,), dtype=int64)\ntf.Tensor([ 0  0  0 31 36  0], shape=(6,), dtype=int64)\ntf.Tensor([72 68  0 41 41 41 43 69 41 43 43], shape=(11,), dtype=int64)\ntf.Tensor([ 0 37], shape=(2,), dtype=int64)\ntf.Tensor([46 46 47 47 47 47 47 47 49 49 47 47 47 47 47 49 47 49 49 49 49 47], shape=(22,), dtype=int64)\ntf.Tensor([2 2 2 2 7 7 0 2 2 9 9 9], shape=(12,), dtype=int64)\ntf.Tensor([ 0  0  0  0 34 35 35], shape=(7,), dtype=int64)\ntf.Tensor([15 28 59], shape=(3,), dtype=int64)\ntf.Tensor([21], shape=(1,), dtype=int64)\ntf.Tensor([ 0 44 44 46 46 45 45 45 60], shape=(9,), dtype=int64)\ntf.Tensor([20 20], shape=(2,), dtype=int64)\ntf.Tensor(\n[ 0  0  0 33 33  0  0  0  0  0  0  0 33 33 33 33 33 33  0  0  0 33 33 33\n 33  0 33], shape=(27,), dtype=int64)\ntf.Tensor([58 58 62 56 56 65 73 73 73 73 58 75 75], shape=(13,), dtype=int64)\ntf.Tensor([33 33 33 33 33], shape=(5,), dtype=int64)\ntf.Tensor([ 0 37 37 14 14 14 14 14 14 37  0 14  0], shape=(13,), dtype=int64)\ntf.Tensor([5 0 0 5 0], shape=(5,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for item in ds_train.take(100):\n",
    "    print(item[\"objects\"][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fip6g2i-B3pi"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='coco',\n",
       "    full_name='coco/2017/1.1.0',\n",
       "    description=\"\"\"\n",
       "    COCO is a large-scale object detection, segmentation, and\n",
       "    captioning dataset.\n",
       "    \n",
       "    Note:\n",
       "     * Some images from the train and validation sets don't have annotations.\n",
       "     * Coco 2014 and 2017 uses the same images, but different train/val/test splits\n",
       "     * The test split don't have any annotations (only images).\n",
       "     * Coco defines 91 classes but the data only uses 80 classes.\n",
       "     * Panotptic annotations defines defines 200 classes but only uses 133.\n",
       "    \"\"\",\n",
       "    config_description=\"\"\"\n",
       "    \n",
       "    This version contains images, bounding boxes and labels for the 2017 version.\n",
       "    \n",
       "    \"\"\",\n",
       "    homepage='http://cocodataset.org/#home',\n",
       "    data_path='/home/nikasmohan/tensorflow_datasets/coco/2017/1.1.0',\n",
       "    download_size=25.20 GiB,\n",
       "    dataset_size=24.98 GiB,\n",
       "    features=FeaturesDict({\n",
       "        'image': Image(shape=(None, None, 3), dtype=tf.uint8),\n",
       "        'image/filename': Text(shape=(), dtype=tf.string),\n",
       "        'image/id': tf.int64,\n",
       "        'objects': Sequence({\n",
       "            'area': tf.int64,\n",
       "            'bbox': BBoxFeature(shape=(4,), dtype=tf.float32),\n",
       "            'id': tf.int64,\n",
       "            'is_crowd': tf.bool,\n",
       "            'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=80),\n",
       "        }),\n",
       "    }),\n",
       "    supervised_keys=None,\n",
       "    splits={\n",
       "        'test': <SplitInfo num_examples=40670, num_shards=64>,\n",
       "        'train': <SplitInfo num_examples=118287, num_shards=256>,\n",
       "        'validation': <SplitInfo num_examples=5000, num_shards=8>,\n",
       "    },\n",
       "    citation=\"\"\"@article{DBLP:journals/corr/LinMBHPRDZ14,\n",
       "      author    = {Tsung{-}Yi Lin and\n",
       "                   Michael Maire and\n",
       "                   Serge J. Belongie and\n",
       "                   Lubomir D. Bourdev and\n",
       "                   Ross B. Girshick and\n",
       "                   James Hays and\n",
       "                   Pietro Perona and\n",
       "                   Deva Ramanan and\n",
       "                   Piotr Doll{'{a}}r and\n",
       "                   C. Lawrence Zitnick},\n",
       "      title     = {Microsoft {COCO:} Common Objects in Context},\n",
       "      journal   = {CoRR},\n",
       "      volume    = {abs/1405.0312},\n",
       "      year      = {2014},\n",
       "      url       = {http://arxiv.org/abs/1405.0312},\n",
       "      archivePrefix = {arXiv},\n",
       "      eprint    = {1405.0312},\n",
       "      timestamp = {Mon, 13 Aug 2018 16:48:13 +0200},\n",
       "      biburl    = {https://dblp.org/rec/bib/journals/corr/LinMBHPRDZ14},\n",
       "      bibsource = {dblp computer science bibliography, https://dblp.org}\n",
       "    }\"\"\",\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "ds_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "InvalidArgumentError",
     "evalue": "Cannot add tensor to the batch: number of elements does not match. Shapes are: [tensor]: [1,1204,800,3], [batch]: [1,800,1066,3]",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/bms/lib/python3.7/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m   2112\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2113\u001b[0;31m       \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2114\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bms/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bms/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2578\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2579\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2580\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bms/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bms/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot add tensor to the batch: number of elements does not match. Shapes are: [tensor]: [1,1204,800,3], [batch]: [1,800,1066,3] [Op:IteratorGetNext]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-527898b9bb41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/bms/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    745\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bms/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    737\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bms/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bms/lib/python3.7/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m   2114\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2115\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_old\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2116\u001b[0;31m       \u001b[0mexecutor_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bms/lib/python3.7/site-packages/tensorflow/python/eager/executor.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;34m\"\"\"Waits for ops dispatched in this executor to finish.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_ExecutorWaitForAllPendingNodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mclear_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot add tensor to the batch: number of elements does not match. Shapes are: [tensor]: [1,1204,800,3], [batch]: [1,800,1066,3]"
     ]
    }
   ],
   "source": [
    "next(iter(ds_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9tt34CM6P-gr"
   },
   "source": [
    "# Load and train the network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r4o3t4PCLagO",
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/12\n",
      "WARNING:tensorflow:From /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py:605: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "WARNING:tensorflow:From /home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py:605: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "/home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/faster_rcnn_fpn_resnet50pytorch/fast_rcnn/sub:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/faster_rcnn_fpn_resnet50pytorch/fast_rcnn/GatherV2_2:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/faster_rcnn_fpn_resnet50pytorch/fast_rcnn/Shape_4:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/faster_rcnn_fpn_resnet50pytorch/fast_rcnn/sub_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/faster_rcnn_fpn_resnet50pytorch/fast_rcnn/GatherV2_5:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/faster_rcnn_fpn_resnet50pytorch/fast_rcnn/Shape_5:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/faster_rcnn_fpn_resnet50pytorch/fast_rcnn/sub_2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/faster_rcnn_fpn_resnet50pytorch/fast_rcnn/GatherV2_8:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/faster_rcnn_fpn_resnet50pytorch/fast_rcnn/Shape_6:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/nikasmohan/miniconda3/envs/bms/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/faster_rcnn_fpn_resnet50pytorch/fast_rcnn/sub_3:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/faster_rcnn_fpn_resnet50pytorch/fast_rcnn/GatherV2_11:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/faster_rcnn_fpn_resnet50pytorch/fast_rcnn/Shape_7:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "     16/Unknown - 163s 8s/step - loss: 3.7418 - rpn_recall: 0.5508 - region_proposal_network_classification_loss: 0.4488 - region_proposal_network_localization_loss: 0.1749 - accuracy: 0.7509 - fg_accuracy: 0.0000e+00 - false_negative: 0.7887 - fast_rcnn_classification_loss: 2.0162 - fast_rcnn_localization_loss: 0.1205"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6f6ed5a9daa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m ]\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mmodel_faster_rcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/bms/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bms/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bms/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bms/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bms/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bms/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/miniconda3/envs/bms/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from kerod.core.standard_fields import BoxField\n",
    "from kerod.core.learning_rate_schedule import LearningRateScheduler\n",
    "from kerod.model import factory\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "# Number of classes of COCO\n",
    "classes = ds_info.features['objects']['label'].names\n",
    "num_classes = len(classes)\n",
    "\n",
    "model_faster_rcnn = factory.build_model(num_classes)\n",
    "base_lr = 0.02\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=base_lr, momentum=0.9)\n",
    "model_faster_rcnn.compile(optimizer=optimizer, loss=None)\n",
    "\n",
    "#The numbering of epochs (LearningRateScheduler) starts at 0.\n",
    "# Which means the decrease will happens on the epoch 9:\n",
    "#(8 + 1: numbering of fit logging starts at 1)\n",
    "callbacks = [\n",
    "    LearningRateScheduler(base_lr, 1, epochs=[8, 10]),\n",
    "    TensorBoard(),\n",
    "    ModelCheckpoint('checkpoints/')\n",
    "]\n",
    "\n",
    "model_faster_rcnn.fit(ds_train, validation_data=ds_test, epochs=12, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights for the serving\n",
    "model_faster_rcnn.save_weights('final_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export a saved model for serving purposes\n",
    "model_faster_rcnn.export_for_serving('serving')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation of few images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from od.utils.drawing import BoxDrawer\n",
    "\n",
    "drawer = BoxDrawer(classes)\n",
    "\n",
    "for i, example in enumerate(ds_val):\n",
    "    inputs, ground_truths = example\n",
    "    out = model_faster_rcnn.predict_on_batch(inputs)\n",
    "    boxes, scores, labels, valid_detections = out\n",
    "    # Will draw the results\n",
    "    drawer(\n",
    "        inputs['images'],\n",
    "        boxes,\n",
    "        scores=scores,\n",
    "        labels=labels,\n",
    "        num_valid_detections=valid_detections\n",
    "    )\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CD14aaUMEudZ"
   },
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ec4-mdjcR_wy"
   },
   "outputs": [],
   "source": [
    "# Load TENSORBOARD\n",
    "%load_ext tensorboard\n",
    "# Start TENSORBOARD\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coco evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "ds_val, ds_info = tfds.load(name=\"coco/2017\", split=\"validation\", shuffle_files=False, with_info=True)\n",
    "# category_ids basicaly map the index 0 the id\n",
    "# e.g: 0 -> 1, 2 -> 3, 79 -> 90\n",
    "category_ids = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Super dirty but the evaluation works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. perform the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from kerod.core.standard_fields import DatasetField, BoxField             \n",
    "from kerod.core.box_ops import convert_to_center_coordinates              \n",
    "from kerod.dataset.preprocessing import resize_to_min_dim                 \n",
    "                                                                       \n",
    "results = []                                                           \n",
    "                                                                       \n",
    "for i, example in enumerate(ds_val): \n",
    "    print(i)\n",
    "    # preprocess image\n",
    "    image = example['image'][:, :, ::-1]\n",
    "    image = resize_to_min_dim(image, 800.0, 1333.0)         \n",
    "    image_information = tf.cast(tf.shape(image)[:2], dtype=tf.float32) \n",
    "    inputs = {\n",
    "        'images': tf.expand_dims(image, axis=0),\n",
    "        'images_information':tf.expand_dims(image_information, axis=0)\n",
    "    }\n",
    "                                                                 \n",
    "    # predict                                                          \n",
    "    boxes, scores, labels, valid_detections = model_faster_rcnn.predict_on_batch(inputs)\n",
    "                                                                       \n",
    "    # Post processing and append to coco results                       \n",
    "    bbox = boxes[0] * tf.tile(\n",
    "        tf.expand_dims(tf.cast(example['image'].shape[:2], tf.float32), axis=0),\n",
    "        [1, 2])                   \n",
    "    scores = scores[0]                                           \n",
    "    labels = labels[0]                                           \n",
    "    for i in range(valid_detections[0]):\n",
    "        # Convert from [y_min, x_min, y_max, x_max] to coco format [x_min, y_min, w, h]\n",
    "        sbox = bbox[i].numpy()\n",
    "        sbox = [sbox[1], sbox[0], sbox[3] - sbox[1], sbox[2] - sbox[0]]\n",
    "        res = {                                                        \n",
    "                'image_id': int(example['image/id']),                       \n",
    "                'category_id': category_ids[int(labels[i])],           \n",
    "                'bbox': [round(float(c), 4) for c in sbox],\n",
    "                'score': round(float(scores[i]), 4),                     \n",
    "            }                                                          \n",
    "        results.append(res)                                            \n",
    "                                                   \n",
    "                                                                       \n",
    "with open('coco_results.json', 'w') as f:                              \n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. install the coco library to compute the performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
    "!unzip annotations_trainval2017.zip\n",
    "!pip install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. compute the performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "with open('coco_results_corrected.json', 'r') as f:                              \n",
    "    results = json.load(f)\n",
    "coco = COCO('./annotations/instances_val2017.json')\n",
    "ret = {}\n",
    "\n",
    "cocoDt = coco.loadRes(results)\n",
    "cocoEval = COCOeval(coco, cocoDt, 'bbox')\n",
    "cocoEval.evaluate()\n",
    "cocoEval.accumulate()\n",
    "cocoEval.summarize()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "coco_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3710jvsc74a57bd09e5b45f77013f2e5edbdd3f84cc58f2e6775f1adfb96c9a7644cc79999760d60",
   "display_name": "Python 3.7.10 64-bit ('bms': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "9e5b45f77013f2e5edbdd3f84cc58f2e6775f1adfb96c9a7644cc79999760d60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}